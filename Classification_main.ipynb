{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## <center> Project ML for Time Series \n",
    "### <center> Feature Selection: A Data Perspective (Part 2)\n",
    "### <center> Classification Problem\n",
    "<center>Work done by : \n",
    "\n",
    "##### <center> Ali HAIDAR: ali.haidar@polytechnique.edu\n",
    "##### <center> Maya AWADA: maya.awada@ip-paris.fr \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, accuracy_score, recall_score, \n",
    "                             precision_score, f1_score, confusion_matrix, mean_absolute_error, \n",
    "                             r2_score, mean_squared_error, mean_absolute_percentage_error)\n",
    "from tabulate import tabulate\n",
    "import features_selection\n",
    "import evaluation\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Sampling Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MHealth dataset is a multi-variate time series dataset that deals with human behavior analysis based on multimodal body sensing. The dataset was found in the UCI machine learning repository. It contains body motion and vital signs recordings for 10 volunteers of various profile while performing 12 different physical activities. The gooal of this classification problem is to predict which activity the subject is doing provided the following features:\n",
    "\n",
    "- ACX:\tAcceleration From The Chest Sensor (X Axis)\n",
    "- ACY:\tAcceleration From The Chest Sensor (Y Axis)\n",
    "- ACZ:\tAcceleration From The Chest Sensor (Z Axis)\n",
    "- ES1:\tElectrocardiogram Signal (Lead 1)\n",
    "- ES2:\tElectrocardiogram Signal (Lead 2)\n",
    "- ALX:\tAcceleration From The Left-Ankle Sensor (X Axis)\n",
    "- ALY:\tAcceleration From The Left-Ankle Sensor (Y Axis)\n",
    "- ALZ:\tAcceleration From The Left-Ankle Sensor (Z Axis)\n",
    "- GLX:\tGyroscope From The Left-Ankle Sensor (X Axis)\n",
    "- GLY:\tGyroscope From The Left-Ankle Sensor (Y Axis)\n",
    "- GLZ:\tGyroscope From The Left-Ankle Sensor (Z Axis)\n",
    "- MLX:\tMagnetometer From The Left-Ankle Sensor (X Axis)\n",
    "- MLY:\tMagnetometer From The Left-Ankle Sensor (Y Axis)\n",
    "- MLZ:\tMagnetometer From The Left-Ankle Sensor (Z Axis)\n",
    "- ARX:\tAcceleration From The Right-Lower-Arm Sensor (X Axis)\n",
    "- ARY:\tAcceleration From The Right-Lower-Arm Sensor (Y Axis)\n",
    "- ARZ:\tAcceleration From The Right-Lower-Arm Sensor (Z Axis)\n",
    "- GRX:\tGyroscope From The Right-Lower-Arm Sensor (X Axis)\n",
    "- GRY:\tGyroscope From The Right-Lower-Arm Sensor (Y Axis)\n",
    "- GRZ:\tGyroscope From The Right-Lower-Arm Sensor (Z Axis)\n",
    "- MRX:\tMagnetometer From The Right-Lower-Arm Sensor (X Axis)\n",
    "- MRY:\tMagnetometer From The Right-Lower-Arm Sensor (Y Axis)\n",
    "- MRZ:\tMagnetometer From The Right-Lower-Arm Sensor (Z Axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(1,11):\n",
    "    data = pd.read_csv(\"classification_data/mHealth_subject\"+str(i)+\".log\", sep=\"\\t\", header=None, encoding=\"utf-8\")\n",
    "    # Sampling Stretgy: For each participant, we randomly select 50 examples of each physical activity\n",
    "    data = data.groupby(data.iloc[:, -1], group_keys=False).apply(lambda x: x.sample(min(len(x), 50)))\n",
    "    data = data.assign(subject = [i for j in range(data.shape[0])])\n",
    "    df = df.append(data)\n",
    "\n",
    "df.columns = ['acx', 'acy', 'acz', 'es1', 'es2', 'alx', 'aly', 'alz', 'glx', 'gly', 'glz', 'mlx', 'mly', 'mlz', 'arx', 'ary', 'arz', 'grx',\n",
    "       'gry', 'grz', 'mrx', 'mry', 'mrz', 'Activity', 'Subject']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.title('Number of Samples per Activity')\n",
    "plt.ylim(0, 600)\n",
    "plt.xlabel(\"Activity\")\n",
    "plt.ylabel(\"Count\")\n",
    "df['Activity'].value_counts().plot.bar(rot=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving Labels to our Activity Values\n",
    "activities_label_dict = {\n",
    "    0: \"None\",\n",
    "    1: \"Standing still\",\n",
    "    2: \"Sitting and relaxing\",\n",
    "    3: \"Lying down\",\n",
    "    4: \"Walking\",\n",
    "    5: \"Climbing stairs\",\n",
    "    6: \"Waist bends forward\",\n",
    "    7: \"Frontal elevation of arms\",\n",
    "    8: \"Knees bending\",\n",
    "    9: \"Cycling\",\n",
    "    10: \"Jogging\",\n",
    "    11: \"Running\",\n",
    "    12: \"Jump front & back\"\n",
    "}\n",
    "\n",
    "df = df.replace({\"Activity\": activities_label_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "round(df[\"Activity\"].value_counts()/df.shape[0]*100,2).plot.pie(autopct= '%2.1f%%',label='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding \n",
    "df = df.drop(['Subject'], axis=1)\n",
    "le = LabelEncoder()\n",
    "df['Activity'] = le.fit_transform(df['Activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20, 15))\n",
    "sns.heatmap(df.corr(), annot = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Activity'], axis=1) \n",
    "y = df['Activity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "ro_scaler = RobustScaler().fit(x)\n",
    "x_scaled = pd.DataFrame(ro_scaler.transform(x), columns = ['acx', 'acy', 'acz', 'es1', 'es2', 'alx', 'aly', 'alz', 'glx', 'gly',\n",
    "       'glz', 'mlx', 'mly', 'mlz', 'arx', 'ary', 'arz', 'grx', 'gry', 'grz',\n",
    "       'mrx', 'mry', 'mrz'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3, stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X Train Shape:', x_train.shape)\n",
    "print('y Train Shape:', y_train.shape, '\\n')\n",
    "print('X Test Shape:', x_test.shape)\n",
    "print('y Test Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary that contains the name of the method and the scores and the features of these method\n",
    "benchmark = {} \n",
    "models = [LogisticRegression(), KNeighborsClassifier(n_neighbors=5)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Features Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    best_score = evaluation.evaluate_model(x_train, y_train, model, stratify = y_train ,  test_size=0.33, number_of_states = 20, acc =  evaluation.eval_metrics)[1]\n",
    "    best_features = x_train.columns\n",
    "    benchmark[type(model).__name__ ] = dict({'w/o FS': dict({'test_score':best_score,  'features':best_features})})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy epsilon sequential feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_features = features_selection.greedy_features_selection(x_train, y_train, models, stratify = np.array(y_train),  number_of_states = 20, metric = evaluation.eval_metrics)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    benchmark[type(model).__name__]['gsfs'] = {'test_score':best_score[i], 'features':best_features[i]}\n",
    "    print(\"The best_score of \" + type(model).__name__ + \" = \", best_score[i])\n",
    "    print(\"The best_features of \" + type(model).__name__  +\" = \", best_features[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using Laplace Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_features = features_selection.laplace_features_selection(x_train, y_train, x_test, models, y_train,  number_of_states = 20, metric = evaluation.eval_metrics)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    benchmark[type(model).__name__]['Laplace'] = {'test_score':best_score[i], 'features':best_features[i]}\n",
    "    print(\"The best_score of \" + type(model).__name__ + \" = \", best_score[i])\n",
    "    print(\"The best_features of \" + type(model).__name__  +\" = \", best_features[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection Using Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_features = features_selection.fisher_feature_selection(x_train, y_train, x_test, models, y_train,  number_of_states = 20, metric = evaluation.eval_metrics)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    benchmark[type(model).__name__]['Fisher'] = {'test_score':best_score[i], 'features':best_features[i]}\n",
    "    print(\"The best_score of \" + type(model).__name__ + \" = \", best_score[i])\n",
    "    print(\"The best_features of \" + type(model).__name__  +\" = \", best_features[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection Using MRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_features = features_selection.MRMR_features_selection(x_train, y_train, x_test, models, y_train,  number_of_states = 20, metric = evaluation.eval_metrics)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    benchmark[type(model).__name__]['MRMR'] = {'test_score':best_score[i], 'features':best_features[i]}\n",
    "    print(\"The best_score of \" + type(model).__name__ + \" = \", best_score[i])\n",
    "    print(\"The best_features of \" + type(model).__name__  +\" = \", best_features[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection Using CIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_features = features_selection.CIFE_features_selection(x_train, y_train, x_test, models, y_train,  number_of_states = 20, metric = evaluation.eval_metrics)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    benchmark[type(model).__name__]['CIFE'] = {'test_score':best_score[i], 'features':best_features[i]}\n",
    "    print(\"The best_score of \" + type(model).__name__ + \" = \", best_score[i])\n",
    "    print(\"The best_features of \" + type(model).__name__  +\" = \", best_features[i])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['model', 'w/o FS', 'Laplace', 'MRMR', 'Fisher', 'CIFE', 'gsfs'])\n",
    "cols = ['w/o FS', 'Laplace', 'MRMR', 'Fisher', 'CIFE', 'gsfs']\n",
    "for i in benchmark.keys():\n",
    "    res = [i]\n",
    "    for z in cols:\n",
    " \n",
    "        if(z in benchmark[i]):\n",
    "            res.append(benchmark[i][z]['test_score'][0])\n",
    "        else:\n",
    "            res.append(np.nan)\n",
    "    results.loc[len(results)] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤══════════════════════╤══════════╤═══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│    │ model                │   w/o FS │   Laplace │     MRMR │   Fisher │     CIFE │     gsfs │\n",
      "╞════╪══════════════════════╪══════════╪═══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│  0 │ LogisticRegression   │ 0.608589 │  0.60982  │ 0.608589 │ 0.609088 │ 0.608589 │ 0.599414 │\n",
      "├────┼──────────────────────┼──────────┼───────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│  1 │ KNeighborsClassifier │ 0.723469 │  0.746205 │ 0.789148 │ 0.814647 │ 0.723469 │ 0.812088 │\n",
      "╘════╧══════════════════════╧══════════╧═══════════╧══════════╧══════════╧══════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(results, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = dict()\n",
    "for i in benchmark.keys():\n",
    "    for j in benchmark[i].keys():\n",
    "    \n",
    "        if(i not in freq):\n",
    "            freq[i] = dict()\n",
    "        if(j not in freq[i]):\n",
    "            freq[i][j] = 0\n",
    "        freq[i][j] += (len(benchmark[i][j]['features'])/x_train.shape[1])*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w/o FS</th>\n",
       "      <th>gsfs</th>\n",
       "      <th>Laplace</th>\n",
       "      <th>Fisher</th>\n",
       "      <th>MRMR</th>\n",
       "      <th>CIFE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>100.0</td>\n",
       "      <td>60.869565</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>100.0</td>\n",
       "      <td>60.869565</td>\n",
       "      <td>91.304348</td>\n",
       "      <td>60.869565</td>\n",
       "      <td>26.086957</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      w/o FS       gsfs    Laplace     Fisher        MRMR  \\\n",
       "LogisticRegression     100.0  60.869565  95.652174  95.652174  100.000000   \n",
       "KNeighborsClassifier   100.0  60.869565  91.304348  60.869565   26.086957   \n",
       "\n",
       "                       CIFE  \n",
       "LogisticRegression    100.0  \n",
       "KNeighborsClassifier  100.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_data = pd.DataFrame(freq).T\n",
    "freq_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
